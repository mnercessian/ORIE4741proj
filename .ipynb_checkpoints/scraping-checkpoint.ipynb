{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.pro-football-reference.com/teams/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ids = pd.read_csv(\"Datasets/nfl_teams_with_spaces.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #finding team abbreviations used by PFR\n",
    "# url = 'https://www.pro-football-reference.com/years/2019/'\n",
    "# reqs = requests.get(url) \n",
    "# soup = BeautifulSoup(reqs.text, 'html.parser') \n",
    "  \n",
    "# urls = [] \n",
    "# for link in soup.find_all('a'): \n",
    "#     print(link.get('href')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_ids\n",
    "# teams = team_ids[\"Abbreviation\"]\n",
    "teams = ['crd', 'atl', 'rav', 'buf', 'car', 'chi', 'cin', 'cle', 'dal', 'den', 'det', 'gnb', 'htx', 'clt',  \n",
    "               'jax', 'kan', 'mia', 'min', 'nwe', 'nor', 'nyg', 'nyj', 'rai', 'phi', 'pit', 'sdg', 'sfo', 'sea',\n",
    "                'ram', 'tam', 'oti', 'was']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a dataframe containing all game data from the given year from Pro Football Reference\n",
    "#with team and year identifiers added\n",
    "def get_year_data(year):\n",
    "    team = teams[0]\n",
    "    year_data = pd.read_html(url + team + \"/\" + str(year) + \".htm\")[1] #take in the first team so we can append in the loop\n",
    "    assert 17 <= year_data.shape[0] <= 21\n",
    "    assert year_data.shape[1] == 25 #confirm we are getting the right table\n",
    "    year_data.insert(0, \"Team\", (teams.index(team) + 1)*np.ones(year_data.shape[0]))\n",
    "    \n",
    "    for team in teams[1:]:\n",
    "        team_data = pd.read_html(url + team + \"/\" + str(year) + \".htm\")[1]  #gets the table from the URL\n",
    "        assert 16 <= team_data.shape[0] <= 21   #16 is the minimum bc week 1 bye is eliminated from table, see 2017 dolphins\n",
    "        assert team_data.shape[1] == 25 #confirm we are getting the right table\n",
    "        team_data.insert(0, \"Team\", (teams.index(team) + 1)*np.ones(team_data.shape[0]))\n",
    "        year_data = year_data.append(team_data)\n",
    "        print(str(year) + ' ' + team)   #for debugging purposes\n",
    "    year_data.insert(0, \"Year\", year*np.ones(year_data.shape[0]))\n",
    "    return year_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulls data over year range and concatenates\n",
    "first_year = 2015\n",
    "last_year = 2019\n",
    "\n",
    "all_data = get_year_data(last_year)\n",
    "for i in range(last_year-1, first_year-1, -1):  \n",
    "    all_data = all_data.append(get_year_data(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.to_csv('Datasets/2015_thru_2019.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_data = pd.read_html(url + teams[16] + \"/\" + '2017' + \".htm\")[1]  #gets the table from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debugging\n",
    "\n",
    "# year = 2017\n",
    "# for team in teams[1:]:\n",
    "#     team_data = pd.read_html(url + team + \"/\" + str(year) + \".htm\")[1]  #gets the table from the URL\n",
    "#     assert 16 <= team_data.shape[0] <= 21\n",
    "#     assert team_data.shape[1] == 25 #confirm we are getting the right table\n",
    "#     team_data.insert(0, \"Team\", (teams.index(team) + 1)*np.ones(team_data.shape[0]))\n",
    "#     print(str(year) + ' ' + team + ' ' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
